{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "#options.add_argument('--enable-print-browser')\n",
    "options.add_argument(\"--headless\")\n",
    "caps = DesiredCapabilities().CHROME\n",
    "caps[\"pageLoadStrategy\"] = \"eager\"\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "import urllib.request\n",
    "\n",
    "tickers = list(pd.read_excel('لیست صندوق_های سهامی.xlsx')['نماد'].values)\n",
    "tickers.sort()\n",
    "\n",
    "def date_gen(item):\n",
    "    text = item.text\n",
    "    loc = text.find('/')\n",
    "    date = int(text[loc - 4 : loc + 6].replace('/', ''))\n",
    "    eslahie = 'اصلاحیه' in text\n",
    "    return date, eslahie\n",
    "\n",
    "def date_check(date, sent):\n",
    "    date_m = (((date // 100) % 100) + 1) % 12\n",
    "    sent_m = ((sent // 100) % 100) % 12\n",
    "    date_y = date // 10000 if date_m != 1 else (date // 10000) + 1\n",
    "    sent_y = sent // 10000\n",
    "    return (date_m == sent_m) and (date_y == sent_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_start = 'https://codal.ir'\n",
    "start_url = \"https://codal.ir/ReportList.aspx?search&Symbol=\"\n",
    "end_url = \"&LetterType=-1&FromDate=1398%2F01%2F01&Isic=46430170&AuditorRef=-1&Audited&NotAudited&IsNotAudited=false&Childs&Mains&Publisher=false&CompanyState=2&Category=3&CompanyType=-1&Consolidatable&NotConsolidatable&PageNumber=\"\n",
    "driver = webdriver.Chrome(options = options, desired_capabilities = caps)\n",
    "for ticker in tickers[75:]:\n",
    "    os.mkdir(os.getcwd() + '/New_Data/' + ticker)\n",
    "    page = '1'\n",
    "    url = start_url + ticker + end_url + page\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'letter-title')))\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    try:\n",
    "        page_num = int(soup.find_all('li', {'title' : 'آخرین صفحه'})[0].find('a')['href'].split('=')[-1])\n",
    "    except:\n",
    "        page_num = 1\n",
    "    a = []\n",
    "    sent = []\n",
    "    a += soup.find_all('a', class_ = 'letter-title')\n",
    "    sent += soup.find_all('td', {'data-heading' : 'زمان ارسال'})\n",
    "    if page_num != 1:\n",
    "        for page in range(2, page_num+1):\n",
    "            url = start_url + ticker + end_url + str(page)\n",
    "            driver.get(url)\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'letter-title')))\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            a += soup.find_all('a', class_ = 'letter-title')\n",
    "            sent += soup.find_all('td', {'data-heading' : 'زمان ارسال'})\n",
    "    dates = [date_gen(x)[0] for x in a]\n",
    "    eslahie = [date_gen(x)[1] for x in a]\n",
    "    sent_dates = [date_gen(td.findChild())[0] for td in sent]\n",
    "    links = [link_start + x['href'] for x in a]\n",
    "    j = 0\n",
    "    for i, link in enumerate(links):\n",
    "        r = requests.get(link, headers = headers, allow_redirects = False)\n",
    "        soup2 = BeautifulSoup(r.text, 'html.parser')\n",
    "        imgs = soup2.find_all('img')\n",
    "        for img in imgs:\n",
    "            if 'xls' in img['src']:\n",
    "                download_link = 'https://codal.ir/Reports/' + img.parent.parent['onclick'].split(\"'\")[1]\n",
    "                excel_file = requests.get(download_link, headers = headers, allow_redirects = True)\n",
    "                if (date_check(dates[i], sent_dates[i])) and not(eslahie[i]):\n",
    "                    open(os.getcwd() + '/New_Data/' + ticker + '/' + str(dates[i]) + '.xlsx', 'wb').write(excel_file.content)\n",
    "                else:\n",
    "                    open(os.getcwd() + '/New_Data/' + ticker + '/' + str(dates[i]) + '_check' + str(j) + '.xlsx', 'wb').write(excel_file.content)\n",
    "                    j += 1\n",
    "                break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
